{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9da0e0be-2abf-41df-98fa-201313d38b1a",
   "metadata": {},
   "source": [
    "# 07 - Generate statistics CSVs\n",
    "Creating a separate notebook to calculate the statistics all in one pass so that I can complete a representative set of CSVs for each instrument class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b187db9e-4aec-44e9-a34f-9d192c16ee56",
   "metadata": {},
   "source": [
    "### Statistics for QARTOD tests in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f2cb034-3e94-4f10-b02c-4fc837a4f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries available from main conda channels or conda-forge\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import dask tools and ProgressBar\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# Import qartod_testing project functions\n",
    "from qartod_testing.data_processing import ooinet_gold_copy_request, get_test_parameters, parse_qartod_executed, qartod_summary_expanded\n",
    "\n",
    "# Import OOI library functions\n",
    "from ooi_data_explorations.common import merge_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "128c1604-566f-4764-99f1-560d861341fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup parameters needed to request data\n",
    "refdes = \"GA01SUMO-RID16-03-CTDBPF000\"\n",
    "method = \"recovered_inst\"\n",
    "stream = \"ctdbp_cdef_instrument_recovered\"\n",
    "\n",
    "# Site, node, and sensor info from deconstructed reference designator\n",
    "# [site, node, sensor] = refdes.split('-', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9839f7e1-94d7-47ba-839f-84a000108f12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2880/3908593300.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Routine in data_processing module from this project to download the gold copy THREDDs datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Variable 'files' contains list of catalog URLs for downloaded datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mooinet_gold_copy_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefdes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/qartod_testing/qartod_testing/data_processing.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(refdes, method, stream, use_dask)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mthredds_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM2M\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_thredds_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefdes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoldCopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# Get the THREDDs catalog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mthredds_catalog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM2M\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_thredds_catalog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthredds_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mdeployments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM2M\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_deployments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefdes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# Remove ancillary files from list of files from THREDDs catalog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0msensor_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM2M\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_catalog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthredds_catalog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeployments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/OOINet/ooinet/M2M.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(refdes, deploy_num, results)\u001b[0m\n\u001b[1;32m    437\u001b[0m                    \"deployCruise\", \"recoverCruise\"]\n\u001b[1;32m    438\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# Generate the table results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;31m# Sort the deployments by deployment number and reset the index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"deploymentNumber\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pioneer_metbk/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "# Routine in data_processing module from this project to download the gold copy THREDDs datasets\n",
    "# Variable 'files' contains list of catalog URLs for downloaded datasets \n",
    "files = ooinet_gold_copy_request(refdes, method, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46111ce7-7288-46ca-b1ed-38709445743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load expected results data from external data folder\n",
    "folder_path = os.path.join(os.path.abspath('../data/external'), method, stream, refdes)\n",
    "expected_files = glob.glob(folder_path+'/*.nc')\n",
    "expected_files.sort() # sorts local test files in alphanumeric order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb52808e-d333-490b-92a1-64ec9d148d1f",
   "metadata": {},
   "source": [
    "#### Gross range test statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ec0e9-f2cc-40ed-a1b1-8d5b6261c619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_statistics(file_paths, test_name):\n",
    "    \"\"\"\n",
    "    Calls other functions to calculate statistics from a set of files and a name of a QARTOD test. The statistics are organized in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "        file_paths: list of paths to each file that will have statistics calculated. File names must include \"deployment00##\".\n",
    "        test_name: string of QARTOD test name, i.e. \"gross_range\", \"climatology\".\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "        statistics: Pandas DataFrame containing statistics on each parameter with a QARTOD test in order of deployment number, then statistics of the full record.\n",
    "        \n",
    "    Version 16 Aug 2023, Kylene M Cooley    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize empty dictionary for statistics\n",
    "    statistics = {}\n",
    "\n",
    "    for m, _ in enumerate(file_paths):\n",
    "        file = file_paths[m]\n",
    "\n",
    "        # get deployment from current file, then open local test and expected test datasets\n",
    "        deployment = re.findall('deployment00[0-2][0-9]', file)[0][-2:]\n",
    "        file_ds = xr.open_dataset(file)\n",
    "\n",
    "        # Get parameters that have QARTOD executed from expected test dataset\n",
    "        test_parameters = get_test_parameters(file_ds)\n",
    "        parameters = list(test_parameters.keys())\n",
    "\n",
    "        # Separate QARTOD test flags in expected test dataset by QARTOD test name\n",
    "        file_ds = parse_qartod_executed(file_ds, parameters)\n",
    "\n",
    "        # Update summary statistics dictionary for each deployment, then for all deployments\n",
    "        print(\"Evaluating statistics on QARTOD flags for deployment \"f\"{deployment}\")\n",
    "        summary_results = qartod_summary_expanded(file_ds, parameters, deployment, test_name)\n",
    "        statistics.update({f\"{m}\" : summary_results })\n",
    "\n",
    "        # Add entry to summary statistics for full data record after last file\n",
    "        if file == file_paths[-1]:\n",
    "            # Open all expected data files and create merged full dataset\n",
    "            merged_ds = [xr.open_dataset(single_file) for single_file in file_paths]\n",
    "            merged_ds = merge_frames(merged_ds)\n",
    "            deployment = \"all\"\n",
    "\n",
    "            # Summary of flags from merged dataset\n",
    "            print(\"Evaluating statistics on QARTOD flags for all deployments\")\n",
    "            merged_ds = parse_qartod_executed(merged_ds, parameters)\n",
    "            summary_results = qartod_summary_expanded(merged_ds, parameters, deployment, test_name)\n",
    "            statistics.update({ \"all\" : summary_results })\n",
    "\n",
    "    # Create data frame from dictionary and check contents\n",
    "    statistics = pd.DataFrame.from_dict(statistics, orient='index')\n",
    "    statistics = statistics.set_index('deployment')\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7294bf-fe60-468c-ae18-443ec4dbd41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_range_stats = collect_statistics(expected_files, \"gross_range\")\n",
    "gross_range_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10893cb5-ffc5-4747-b508-a4c616818c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data frames as CSVs\n",
    "folder_path = os.path.join(os.path.abspath('../data/processed'), method, stream, refdes)\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "gross_range_stats.to_csv(folder_path+f\"/gross_range-{refdes}-flag_statistics.csv\", na_rep='NaN', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c35ad-a8e6-4139-bc12-c7486c39636c",
   "metadata": {},
   "source": [
    "#### Climatology test statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f9b64-92c1-4610-b20c-2e193f1d5755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pioneer_metbk",
   "language": "python",
   "name": "pioneer_metbk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
