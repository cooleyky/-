{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75d71717",
   "metadata": {},
   "source": [
    "### Import modules used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "231381dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "import io\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8cc4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OOINet library\n",
    "sys.path.append(\"c:\\\\Users\\\\cooleyky\\\\Documents\\\\GitHub\\\\OOINet\") # this is what was missing from the steps I followed to install ooinet and ooi-data-explorations as local dev repo\n",
    "from ooinet import M2M\n",
    "from ooinet.Instrument.common import process_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9004d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions from ooi-data-explorations library\n",
    "sys.path.append(\"c:\\\\Users\\\\cooleyky\\\\Documents\\\\GitHub\\\\ooi-data-explorations\\\\python\") # why did the initial install not include this?\n",
    "from ooi_data_explorations.uncabled.process_dosta import dosta_datalogger\n",
    "from ooi_data_explorations.combine_data import combine_datasets\n",
    "from ooi_data_explorations import common as ooi_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4949151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dask tools and ProgressBar\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef015859",
   "metadata": {},
   "source": [
    "### Define data parameters and routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86144467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameters needed to request data\n",
    "refdes = \"CP01CNSM-MFD37-03-CTDBPD000\"              # Coastal Pioneer Array (NES) - Central Surface Mooring CTD Bottom-pumped, is this the same as site, node, sensor?\n",
    "method = \"recovered_inst\"                           # non-decimated data from recovered instrument\n",
    "stream = \"ctdbp_cdef_instrument_recovered\"          # name of data stream\n",
    "# Site, node, and sensor info from deconstructed reference designator\n",
    "site = \"CP01CNSM\"\n",
    "node = \"MFD37\"\n",
    "sensor = \"03-CTDBPD000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbf33ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic preprocessing routine to do some generic dataset cleaning/processing\n",
    "@dask.delayed\n",
    "def preprocess(ds):\n",
    "    ds = xr.open_dataset(ds)\n",
    "    ds = process_file(ds)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119c89b2",
   "metadata": {},
   "source": [
    "### QARTOD in Production: Request data from the THREDDS catalog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2ab43be",
   "metadata": {},
   "source": [
    "##### Using mostly OOINet module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38249131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the gold copy THREDDs datasets\n",
    "thredds_url = M2M.get_thredds_url(refdes, method, stream, goldCopy=True)\n",
    "\n",
    "# Get the THREDDs catalog\n",
    "thredds_catalog = M2M.get_thredds_catalog(thredds_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a267ad55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['catalog.html?dataset=ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0001_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20131121T181601-20140217T130601.nc',\n",
       " 'catalog.html?dataset=ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0003_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20150507T173501-20151023T193501.nc',\n",
       " 'catalog.html?dataset=ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0005_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20160513T140200-20160808T180200.nc',\n",
       " 'catalog.html?dataset=ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0006_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20161013T184501-20170122T060001.nc',\n",
       " 'catalog.html?dataset=ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0007_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20170609T143001-20170830T155050.nc',\n",
       " 'catalog.html?dataset=ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0008_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20171029T141501-20180329T193001.nc',\n",
       " 'catalog.html?dataset=ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0009_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20180324T214501-20181029T123001.nc',\n",
       " 'catalog.html?dataset=ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0010_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20181030T020001-20181114T081501.nc',\n",
       " 'catalog.html?dataset=ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0011_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20190406T144501-20190926T170001.nc',\n",
       " 'catalog.html?dataset=ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0012_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20190927T183001-20201106T130001.nc',\n",
       " 'catalog.html?dataset=ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0013_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20201029T150001-20210403T100004.nc',\n",
       " 'catalog.html?dataset=ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0014_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20210331T154501-20211103T164501.nc',\n",
       " 'catalog.html?dataset=ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0015_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20211103T144501-20220413T120001.nc',\n",
       " 'catalog.html?dataset=ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0016_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20220413T120002-20221111T131501.nc']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the THREDDs catalog\n",
    "sensor_files, ancillary_files = M2M.clean_catalog(thredds_catalog, stream) \n",
    "# removes entries from thredds_catalog if they do not match the stream, or are used in processing data from the selected stream\n",
    "sensor_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af33fd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0001_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20131121T181601-20140217T130601.nc',\n",
       " 'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0003_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20150507T173501-20151023T193501.nc',\n",
       " 'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0005_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20160513T140200-20160808T180200.nc',\n",
       " 'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0006_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20161013T184501-20170122T060001.nc',\n",
       " 'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0007_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20170609T143001-20170830T155050.nc',\n",
       " 'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0008_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20171029T141501-20180329T193001.nc',\n",
       " 'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0009_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20180324T214501-20181029T123001.nc',\n",
       " 'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0010_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20181030T020001-20181114T081501.nc',\n",
       " 'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0011_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20190406T144501-20190926T170001.nc',\n",
       " 'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0012_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20190927T183001-20201106T130001.nc',\n",
       " 'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0013_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20201029T150001-20210403T100004.nc',\n",
       " 'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0014_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20210331T154501-20211103T164501.nc',\n",
       " 'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0015_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20211103T144501-20220413T120001.nc',\n",
       " 'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0016_CP01CNSM-MFD37-03-CTDBPD000-recovered_inst-ctdbp_cdef_instrument_recovered_20220413T120002-20221111T131501.nc']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now build the url to access the data\n",
    "sensor_files = [re.sub(\"catalog.html\\?dataset=\", M2M.URLS[\"goldCopy_dodsC\"], file) for file in sensor_files]\n",
    "sensor_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12899b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "zs = [preprocess(file) for file in sensor_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf813cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the datasets\n",
    "with ProgressBar():\n",
    "    data = xr.concat([ds.chunk() for ds in dask.compute(*zs)], dim=\"time\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0d49e9e",
   "metadata": {},
   "source": [
    "##### Using ooi_data_explorations modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a56034e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 15 data file(s) from the OOI Gold Copy THREDSS catalog\n",
      "Downloading and Processing Data Files: 100%|██████████| 15/15 [00:18<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load data with ooi_common module\n",
    "data = ooi_common.load_gc_thredds(site,node,sensor,method,stream,use_dask=True)    # Request the gold copy data through THREDDs catalog\n",
    "# The potential error I see here that maybe Andrew was trying to work around was not getting ancillary files through this method\n",
    "# load_gc_thredds() also calls process_file() within gc_collect() so we achieve the same preprocessing as in the preprocess() defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfb1da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the data with a unique name\n",
    "ds_prod = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81992ff3",
   "metadata": {},
   "source": [
    "### QARTOD in Development: Request data from dev1 server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd20da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub in ooinet-dev1-west.intra.oceanobservatories.org into the avaialbe API urls\n",
    "Dev01_urls = {}\n",
    "for key in M2M.URLS:\n",
    "    url = M2M.URLS.get(key)\n",
    "    if \"opendap\" in url:\n",
    "        dev1_url = re.sub(\"opendap\", \"opendap-dev1-west.intra\", url)\n",
    "    else:\n",
    "        dev1_url = re.sub(\"ooinet\",\"ooinet-dev1-west.intra\", url)\n",
    "    Dev01_urls[key] = dev1_url\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d09296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following example is just the same as the ooinet gold copy! I'm not sure how the dev1 urls above get used.\n",
    "# We can't use any of the following because the development environment doesn't have a gold copy\n",
    "# Use the gold copy THREDDs datasets\n",
    "thredds_url = M2M.get_thredds_url(refdes, method, stream, goldCopy=True) # in this example we recycle refdes, method, stream\n",
    "\n",
    "# Get the THREDDs catalog\n",
    "thredds_catalog = M2M.get_thredds_catalog(thredds_url)\n",
    "\n",
    "# Clean the THREDDs catalog\n",
    "sensor_files, ancillary_files = M2M.clean_catalog(thredds_catalog, stream)\n",
    "\n",
    "# Now build the url to access the data\n",
    "sensor_files = [re.sub(\"catalog.html\\?dataset=\", M2M.URLS[\"goldCopy_dodsC\"], file) for file in sensor_files]\n",
    "zs = [preprocess(file) for file in sensor_files]\n",
    "\n",
    "# Load all the datasets\n",
    "with ProgressBar():\n",
    "    data = xr.concat([ds.chunk() for ds in dask.compute(*zs)], dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c326511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapting ooi_data_explorations.common.process_file() for Dev01 datasets\n",
    "\n",
    "url = re.sub('catalog.html\\?dataset=', Dev01_urls, catalog_file)\n",
    "r = SESSION.get(url, timeout=(3.05, 120))\n",
    "if r.ok:\n",
    "    if use_dask:\n",
    "        ds = xr.open_dataset(io.BytesIO(r.content), decode_cf=False, chunks=10000)\n",
    "    else:\n",
    "        ds = xr.load_dataset(io.BytesIO(r.content), decode_cf=False)\n",
    "else:\n",
    "    failed_file = catalog_file.rpartition('/')\n",
    "    warnings.warn('Failed to download %s' % failed_file[-1])\n",
    "    return None\n",
    "\n",
    "# addresses error in how the *_qartod_executed variables are set\n",
    "# qartod_pattern = re.compile(r'^.+_qartod_executed$')\n",
    "# for v in ds.variables:\n",
    "#     if qartod_pattern.match(v):\n",
    "#         # the shape of the QARTOD executed variables should compare to the provenance variable\n",
    "#         if ds[v].shape != ds['provenance'].shape:\n",
    "#             ds = ds.drop_vars(v)\n",
    "\n",
    "# convert the dimensions from obs to time and get rid of obs and other variables we don't need\n",
    "ds = ds.swap_dims({'obs': 'time'})\n",
    "ds = ds.reset_coords()\n",
    "keys = ['obs', 'id', 'provenance', 'driver_timestamp', 'ingestion_timestamp',\n",
    "        'port_timestamp', 'preferred_timestamp']\n",
    "for key in keys:\n",
    "    if key in ds.variables:\n",
    "        ds = ds.drop_vars(key)\n",
    "\n",
    "# since the CF decoding of the time is failing, explicitly reset all instances where the units are\n",
    "# seconds since 1900-01-01 to the correct CF units and convert the values to datetime64[ns] types\n",
    "time_pattern = re.compile(r'^seconds since 1900-01-01.*$')\n",
    "ntp_date = np.datetime64('1900-01-01')\n",
    "for v in ds.variables:\n",
    "    if 'units' in ds[v].attrs.keys():\n",
    "        if isinstance(ds[v].attrs['units'], str):  # because some units use non-standard characters...\n",
    "            if time_pattern.match(ds[v].attrs['units']):\n",
    "                del(ds[v].attrs['_FillValue'])  # no fill values for time!\n",
    "                ds[v].attrs['units'] = 'seconds since 1900-01-01T00:00:00.000Z'\n",
    "                np_time = ntp_date + (ds[v] * 1e9).astype('timedelta64[ns]')\n",
    "                ds[v] = np_time\n",
    "\n",
    "# sort by time\n",
    "ds = ds.sortby('time')\n",
    "\n",
    "# clear-up some global attributes we will no longer be using\n",
    "keys = ['DODS.strlen', 'DODS.dimName', 'DODS_EXTRA.Unlimited_Dimension', '_NCProperties', 'feature_Type']\n",
    "for key in keys:\n",
    "    if key in ds.attrs:\n",
    "        del(ds.attrs[key])\n",
    "\n",
    "if ds.encoding['unlimited_dims']:\n",
    "    del ds.encoding['unlimited_dims']\n",
    "\n",
    "# resetting cdm_data_type from Point to Station and the featureType from point to timeSeries\n",
    "ds.attrs['cdm_data_type'] = 'Station'\n",
    "ds.attrs['featureType'] = 'timeSeries'\n",
    "\n",
    "# update some global attributes\n",
    "ds.attrs['acknowledgement'] = 'National Science Foundation'\n",
    "ds.attrs['comment'] = 'Data collected from the OOI Dev01 M2M API and reworked for use in locally stored NetCDF files.'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ae7494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the data with a unique name\n",
    "ds_dev = data.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf34610",
   "metadata": {},
   "source": [
    "### Save datasets to interim data folder for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1280270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# something along the lines of write_nc(), xr.save_dataset?\n",
    "# call the data file datasets_for_testing.nc \n",
    "# I think we will test datasets in production and development separately, so maybe making separate files for those types"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
